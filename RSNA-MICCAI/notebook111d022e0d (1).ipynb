{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"SUBMISSION = True","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3D Convolution Network for Brain Tumor Detection\n\n### Table of Content\n\n- library importation\n- statistical exploration\n- helper functions\n- 1st prototype: NNModel\n- dataset generation\n- training procedure\n- improved model: BTD (Brain Tumor Detection)\n- post training analysis\n- submission","metadata":{}},{"cell_type":"markdown","source":"## library importation","metadata":{}},{"cell_type":"code","source":"import os    # operating system\nimport re    # regular expression\nimport glob   # read files with regular expression\nimport numpy as np   # numerical\nimport scipy as sp    # scientific\nimport pandas as pd    # table management\nimport seaborn as sns    # plot for data scientist\nfrom PIL import Image    # image management\nfrom tqdm import tqdm    # progress bar\n\nimport matplotlib.pyplot as plt    # the most popular plot lib\nfrom mpl_toolkits.mplot3d import Axes3D    \n%matplotlib inline\n\nimport pydicom   # .dicom files management\nfrom pydicom.pixel_data_handlers.util import apply_voi_lut\n\nimport tensorflow as tf   # deep learning\nimport tensorflow.keras as keras\n\n# For gif creation\nimport imageio","metadata":{"execution":{"iopub.status.busy":"2021-08-07T04:03:05.171483Z","iopub.execute_input":"2021-08-07T04:03:05.171822Z","iopub.status.idle":"2021-08-07T04:03:05.182578Z","shell.execute_reply.started":"2021-08-07T04:03:05.171792Z","shell.execute_reply":"2021-08-07T04:03:05.181484Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# For showing gif, comment this block for submission\n!pip install -q git+https://github.com/tensorflow/docs\nfrom tensorflow_docs.vis import embed","metadata":{"execution":{"iopub.status.busy":"2021-08-07T04:03:05.184193Z","iopub.execute_input":"2021-08-07T04:03:05.184617Z","iopub.status.idle":"2021-08-07T04:03:27.185846Z","shell.execute_reply.started":"2021-08-07T04:03:05.184583Z","shell.execute_reply":"2021-08-07T04:03:27.184971Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Statistic Exploration","metadata":{}},{"cell_type":"code","source":"train_df = pd.read_csv('../input/rsna-miccai-brain-tumor-radiogenomic-classification/train_labels.csv')\n\nprint(\"num of rows:\", len(train_df))\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-07T04:03:27.18955Z","iopub.execute_input":"2021-08-07T04:03:27.189816Z","iopub.status.idle":"2021-08-07T04:03:27.210701Z","shell.execute_reply.started":"2021-08-07T04:03:27.18979Z","shell.execute_reply":"2021-08-07T04:03:27.209997Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(16,5))\nax = sns.countplot(data=train_df, y=\"MGMT_value\")\nax.set_title(\"Distridution of Labels\")\nprint(train_df.MGMT_value.value_counts())","metadata":{"execution":{"iopub.status.busy":"2021-08-07T04:03:27.213716Z","iopub.execute_input":"2021-08-07T04:03:27.213962Z","iopub.status.idle":"2021-08-07T04:03:27.380458Z","shell.execute_reply.started":"2021-08-07T04:03:27.213939Z","shell.execute_reply":"2021-08-07T04:03:27.379453Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Helper Functions","metadata":{}},{"cell_type":"code","source":"def ReadMRI(path, voi_lut=True, fix_monochrome=True):\n    dicom = pydicom.read_file(path)\n    \n    if voi_lut:\n        data = apply_voi_lut(dicom.pixel_array, dicom)\n    else:\n        data = dicom.pixel_array\n        \n    if fix_monochrome and dicom.PhotometricInterpretation == \"MONOCHROME1\":\n        data = np.amax(data) - data\n        \n    data = data - np.min(data)\n    data = data / np.max(data)\n    data = (data * 255).astype(np.uint8)\n    \n    return data\n\n\n# https://stackoverflow.com/a/2669120/7636462\ndef sorted_nicely(l): \n    \"\"\" Sort the given iterable in the way that humans expect.\"\"\" \n    convert = lambda text: int(text) if text.isdigit() else text \n    alphanum_key = lambda key: [ convert(c) for c in re.split('([0-9]+)', key) ] \n    return sorted(l, key = alphanum_key)\n\n\ndef get_patient_id(patient_id):\n    if patient_id < 10:\n        return '0000'+str(patient_id)\n    elif patient_id >= 10 and patient_id < 100:\n        return '000'+str(patient_id)\n    elif patient_id >=100 and patient_id < 1000:\n        return '00'+str(patient_id)\n    else:\n        return '0'+str(patient_id)\n    \n    \ndef to_gif(images, savepath, fps=25):\n  imageio.mimsave(savepath, images, fps=fps)\n  return embed.embed_file(savepath)\n\n\ndef resize(image, target_size):\n    zoom_factor = [target_size[i] / image.shape[i] for i in range(len(image.shape))]\n    image = sp.ndimage.zoom(image, zoom=zoom_factor)\n    \n    return image\n\n    \ndef save_hidden_images(sample, model, epoch, itr):\n    prob = model(sample)\n    \n    for i, conv in enumerate(model.convs):\n        for j in range(conv.output_.shape[-1]):\n            basepath = f\"/kaggle/working/train/images_{epoch}/iteration_{itr}/conv_{i}\"\n            os.makedirs(basepath, exist_ok=True)\n            to_gif(conv.output_[0, :, :, :, i], savepath=os.path.join(basepath, f\"channel_{j}.gif\"))\n\n\n","metadata":{"execution":{"iopub.status.busy":"2021-08-07T04:03:27.38201Z","iopub.execute_input":"2021-08-07T04:03:27.382374Z","iopub.status.idle":"2021-08-07T04:03:27.395687Z","shell.execute_reply.started":"2021-08-07T04:03:27.382335Z","shell.execute_reply":"2021-08-07T04:03:27.394581Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# show a chosen patient's data\n# patient_ids = os.listdir('../input/rsna-miccai-brain-tumor-radiogenomic-classification/train')\n# IDX = np.random.choice(len(patient_ids))\n# patient_id = patient_ids[IDX]\n","metadata":{"execution":{"iopub.status.busy":"2021-08-07T04:03:27.397315Z","iopub.execute_input":"2021-08-07T04:03:27.397802Z","iopub.status.idle":"2021-08-07T04:03:27.410148Z","shell.execute_reply.started":"2021-08-07T04:03:27.397764Z","shell.execute_reply":"2021-08-07T04:03:27.40937Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def read_patient(pid):\n    # transform pid \n    label = train_df.loc[pid, 'MGMT_value']\n    _patient_id = get_patient_id(train_df.loc[pid, 'BraTS21ID'])\n    \n    data = {}\n    for scantype in ['FLAIR', 'T1w', 'T1wCE', 'T2w']:\n        # read data\n        scan_base = f'../input/rsna-miccai-brain-tumor-radiogenomic-classification/train/{_patient_id}/{scantype}/' \n\n        scan_filenames = os.listdir(scan_base)\n        scan_filenames = sorted_nicely(scan_filenames)\n        scan_filenames =[os.path.join(scan_base, filename) for filename in scan_filenames]\n\n        scan_data = [ReadMRI(filename) for filename in scan_filenames]\n        scan_data = np.stack(scan_data, axis=0)\n    \n        data[scantype] = scan_data\n    \n#     print(_patient_id)\n    return data, label\n    \n# data, label = read_patient(21)\n# print(data['FLAIR'].shape)\n# print(data['T1w'].shape)\n# print(data['T1wCE'].shape)\n# print(data['T2w'].shape)\n\n# print(label)","metadata":{"execution":{"iopub.status.busy":"2021-08-07T04:03:27.411527Z","iopub.execute_input":"2021-08-07T04:03:27.411923Z","iopub.status.idle":"2021-08-07T04:03:27.422879Z","shell.execute_reply.started":"2021-08-07T04:03:27.411887Z","shell.execute_reply":"2021-08-07T04:03:27.42201Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def read_test_patient(patient_idx):\n    data = {}\n    for scantype in ['FLAIR', 'T1w', 'T1wCE', 'T2w']:\n        # read data\n        scan_base = f'../input/rsna-miccai-brain-tumor-radiogenomic-classification/test/{patient_idx}/{scantype}/' \n\n        scan_filenames = os.listdir(scan_base)\n        scan_filenames = sorted_nicely(scan_filenames)\n        scan_filenames =[os.path.join(scan_base, filename) for filename in scan_filenames]\n\n        scan_data = [ReadMRI(filename) for filename in scan_filenames]\n        scan_data = np.stack(scan_data, axis=0)\n    \n        data[scantype] = scan_data\n    \n    return data\n    ","metadata":{"execution":{"iopub.status.busy":"2021-08-07T04:03:27.425796Z","iopub.execute_input":"2021-08-07T04:03:27.426222Z","iopub.status.idle":"2021-08-07T04:03:27.434807Z","shell.execute_reply.started":"2021-08-07T04:03:27.426149Z","shell.execute_reply":"2021-08-07T04:03:27.43402Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# resized_image = resize(data['FLAIR'], (100, 256, 256))","metadata":{"execution":{"iopub.status.busy":"2021-08-07T04:03:27.437437Z","iopub.execute_input":"2021-08-07T04:03:27.437994Z","iopub.status.idle":"2021-08-07T04:03:27.44503Z","shell.execute_reply.started":"2021-08-07T04:03:27.437941Z","shell.execute_reply":"2021-08-07T04:03:27.444073Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# resized_image.shape","metadata":{"execution":{"iopub.status.busy":"2021-08-07T04:03:27.44668Z","iopub.execute_input":"2021-08-07T04:03:27.447113Z","iopub.status.idle":"2021-08-07T04:03:27.45455Z","shell.execute_reply.started":"2021-08-07T04:03:27.447071Z","shell.execute_reply":"2021-08-07T04:03:27.453665Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from tensorflow_docs.vis import embed\n\n# savepath = '/kaggle/working/1_FLAIR.gif'\n# to_gif(data['FLAIR'], savepath)","metadata":{"execution":{"iopub.status.busy":"2021-08-07T04:03:27.456113Z","iopub.execute_input":"2021-08-07T04:03:27.456573Z","iopub.status.idle":"2021-08-07T04:03:27.465041Z","shell.execute_reply.started":"2021-08-07T04:03:27.456531Z","shell.execute_reply":"2021-08-07T04:03:27.464086Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# savepath = '/kaggle/working/1_T1w.gif'\n# to_gif(data['T1w'], savepath)","metadata":{"execution":{"iopub.status.busy":"2021-08-07T04:03:27.468102Z","iopub.execute_input":"2021-08-07T04:03:27.46856Z","iopub.status.idle":"2021-08-07T04:03:27.475146Z","shell.execute_reply.started":"2021-08-07T04:03:27.468526Z","shell.execute_reply":"2021-08-07T04:03:27.474208Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# savepath = '/kaggle/working/1_T1wCE.gif'\n# to_gif(data['T1wCE'], savepath)","metadata":{"execution":{"iopub.status.busy":"2021-08-07T04:03:27.476266Z","iopub.execute_input":"2021-08-07T04:03:27.476491Z","iopub.status.idle":"2021-08-07T04:03:27.48758Z","shell.execute_reply.started":"2021-08-07T04:03:27.476471Z","shell.execute_reply":"2021-08-07T04:03:27.48676Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# savepath = '/kaggle/working/1_T2w.gif'\n# to_gif(data['T2w'], savepath)","metadata":{"execution":{"iopub.status.busy":"2021-08-07T04:03:27.488873Z","iopub.execute_input":"2021-08-07T04:03:27.489291Z","iopub.status.idle":"2021-08-07T04:03:27.496219Z","shell.execute_reply.started":"2021-08-07T04:03:27.489258Z","shell.execute_reply":"2021-08-07T04:03:27.495365Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# def plot_3d_image(image, interval=10):\n#     xx, yy = np.meshgrid(np.linspace(0,1,image.shape[1]), np.linspace(0,1,image.shape[2]))\n\n#     fig = plt.figure()\n#     ax = Axes3D(fig)\n#     for i in tqdm(range(len(image))):\n#         zz = np.zeros_like(xx) + interval\n#         data = image[i]\n#         ax.plot_surface(xx, yy, zz, rstride=1, cstride=1, facecolors=plt.cm.BrBG(data), shade=False)\n    \n#     plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-07T04:03:27.499307Z","iopub.execute_input":"2021-08-07T04:03:27.499632Z","iopub.status.idle":"2021-08-07T04:03:27.506021Z","shell.execute_reply.started":"2021-08-07T04:03:27.499605Z","shell.execute_reply":"2021-08-07T04:03:27.504959Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 1st Prototype: NNModel","metadata":{}},{"cell_type":"code","source":"class NNModel(keras.Model):\n    def __init__(self):\n        super().__init__()\n        \n        self.num_conv_layers = 6\n        self.conv_filters =      [16,     64,     128,        256,      512,         512]\n        self.conv_kernel_sizes = [7,      7,      7,          7,        (5, 7, 7),   4]\n        self.pool_kernel_sizes = [3,      3,      (1, 3, 3),  None,     None,        None]\n        self.bm_or_not =         [True,   True,   True,       True,     True,        True]\n        \n        self.convs = []\n        self.pools = []\n        self.bms   = []\n        \n        for i in range(self.num_conv_layers):\n            if self.conv_filters[i]:\n                self.convs.append(keras.layers.Conv3D(self.conv_filters[i], self.conv_kernel_sizes[i], activation='relu'))\n            else:\n                self.convs.append(None)\n            \n            if self.pool_kernel_sizes[i]:\n                self.pools.append(keras.layers.MaxPool3D(pool_size=self.pool_kernel_sizes[i], strides=None, padding='valid', data_format=None))\n            else:\n                self.pools.append(None)\n                \n            if self.bm_or_not[i]:\n                self.bms.append(keras.layers.BatchNormalization())\n            else:\n                self.bms.append(None)\n\n        self.flatten = keras.layers.Flatten()\n        \n        self.num_linear_layers = 2\n        self.linear_dims = [512, 1]\n        \n        self.linears = []\n        \n        for i in range(self.num_linear_layers):\n            self.linears.append(keras.layers.Dense(self.linear_dims[i], activation='relu'))\n        \n    def call(self, x, verbos=0):\n        for i in range(self.num_conv_layers):\n            if self.convs[i]:\n                x = self.convs[i](x)\n            if self.pools[i]:\n                x = self.pools[i](x)\n            if self.bms[i]:\n                x = self.bms[i](x)\n            \n            if verbos > 0:\n                print('ok', x.shape)\n            \n        x = self.flatten(x)\n        \n        for i in range(self.num_linear_layers):\n            x = self.linears[i](x)\n            if verbos > 0:\n                print('ok', x.shape)\n        \n        return x","metadata":{"execution":{"iopub.status.busy":"2021-08-07T04:03:27.507433Z","iopub.execute_input":"2021-08-07T04:03:27.507836Z","iopub.status.idle":"2021-08-07T04:03:27.522701Z","shell.execute_reply.started":"2021-08-07T04:03:27.507801Z","shell.execute_reply":"2021-08-07T04:03:27.521673Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"nn = NNModel()\nnn.build(input_shape=(None, 204, 512, 512, 1))\nnn.summary()","metadata":{"execution":{"iopub.status.busy":"2021-08-07T04:03:27.52426Z","iopub.execute_input":"2021-08-07T04:03:27.524686Z","iopub.status.idle":"2021-08-07T04:03:29.568365Z","shell.execute_reply.started":"2021-08-07T04:03:27.524651Z","shell.execute_reply":"2021-08-07T04:03:29.567407Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# x = tf.random.normal((1, 204, 512, 512, 1))\n# output = nn(x)","metadata":{"execution":{"iopub.status.busy":"2021-08-07T04:03:29.572441Z","iopub.execute_input":"2021-08-07T04:03:29.574448Z","iopub.status.idle":"2021-08-07T04:03:29.579896Z","shell.execute_reply.started":"2021-08-07T04:03:29.574403Z","shell.execute_reply":"2021-08-07T04:03:29.578628Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# print(output.shape)","metadata":{"execution":{"iopub.status.busy":"2021-08-07T04:03:29.58344Z","iopub.execute_input":"2021-08-07T04:03:29.585412Z","iopub.status.idle":"2021-08-07T04:03:29.593153Z","shell.execute_reply.started":"2021-08-07T04:03:29.585371Z","shell.execute_reply":"2021-08-07T04:03:29.592077Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Dataset Generation","metadata":{}},{"cell_type":"code","source":"def get_brain_tumor_train_dataset(using='FLAIR', maxlen=None):\n    train_df = pd.read_csv('../input/rsna-miccai-brain-tumor-radiogenomic-classification/train_labels.csv')\n    \n    labels = list(train_df['MGMT_value'])\n    if maxlen:\n        labels = labels[:maxlen]\n        \n    \n        \n    def data_generator():\n        data_size = min(maxlen, len(train_df)) if maxlen else len(train_df)\n        random_idx = list(range(data_size))\n        np.random.shuffle(random_idx)\n        for i in range(data_size):\n            j = random_idx[i]\n            data, label = read_patient(j)\n            img = data[using]\n            img = resize(img, (128, 256, 256))\n            img = img.reshape(128, 256, 256, 1).astype(float)\n            yield img, labels[j]\n\n    \n    train_dataset = tf.data.Dataset.from_generator(data_generator, (tf.float32, tf.int64))\n    \n    print(\"successfully load dataset\")\n    \n    return train_dataset","metadata":{"execution":{"iopub.status.busy":"2021-08-07T04:03:29.594531Z","iopub.execute_input":"2021-08-07T04:03:29.597876Z","iopub.status.idle":"2021-08-07T04:03:29.613206Z","shell.execute_reply.started":"2021-08-07T04:03:29.597679Z","shell.execute_reply":"2021-08-07T04:03:29.612094Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_brain_tumor_test_dataset(using='FLAIR'):\n    test_df = pd.read_csv(\"../input/rsna-miccai-brain-tumor-radiogenomic-classification/train_labels.csv\")\n    \n    def data_generator():\n        for i in range(len(test_df)):\n            patient_idx = test_df.loc[i, \"BraTS21ID\"]\n            patient_idx = get_patient_id(patient_idx)\n            data = read_test_patient(patient_idx)\n            img = data[using]\n            img = resize(img, (128, 256, 256))\n            img = img.reshape(1, 128, 256, 256, 1).astype(float)\n            yield img\n\n    \n    train_dataset = tf.data.Dataset.from_generator(data_generator, (tf.float32))\n    \n    print(\"successfully load test dataset\")\n    \n    return train_dataset","metadata":{"execution":{"iopub.status.busy":"2021-08-07T04:03:29.618056Z","iopub.execute_input":"2021-08-07T04:03:29.620686Z","iopub.status.idle":"2021-08-07T04:03:29.630268Z","shell.execute_reply.started":"2021-08-07T04:03:29.620644Z","shell.execute_reply":"2021-08-07T04:03:29.629339Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample = read_patient(21)[0]['FLAIR'].astype(float)\nsample = resize(sample, (128, 256, 256))\nsample = sample.reshape(1, 128, 256, 256, 1)\nsample = tf.convert_to_tensor(sample)","metadata":{"execution":{"iopub.status.busy":"2021-08-07T04:03:29.634369Z","iopub.execute_input":"2021-08-07T04:03:29.636884Z","iopub.status.idle":"2021-08-07T04:03:44.85996Z","shell.execute_reply.started":"2021-08-07T04:03:29.636823Z","shell.execute_reply":"2021-08-07T04:03:44.859131Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Training Procedure","metadata":{}},{"cell_type":"code","source":"def train(train_dataset, model, batch_size=5, EPOCHS=3, submission=False):\n    dataset = train_dataset.batch(batch_size)\n    \n    optimizer = keras.optimizers.Adam()\n    loss_func = keras.losses.BinaryCrossentropy()\n    \n    \n    @tf.function\n    def train_step(images, label):\n        with tf.GradientTape() as tape:\n            output = model(images)\n            loss = loss_func(label, output)\n\n        gradients = tape.gradient(loss, model.trainable_variables)\n        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n    \n    \n    for epoch in range(EPOCHS):\n        print(f\"start epoch {epoch}\")\n        for itr, (images, label) in tqdm(enumerate(dataset)):\n            train_step(images, label)\n\n            if itr % 100 == 0 and (not submission):\n                save_hidden_images(sample, model, epoch + 1, itr + 1)\n\n#         checkpoint.save(file_prefix = checkpoint_prefix)\n\n  # 最后一个 epoch 结束后生成图片\n    save_hidden_images(sample, model, \"last\", 0)\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2021-08-07T04:03:44.863662Z","iopub.execute_input":"2021-08-07T04:03:44.863939Z","iopub.status.idle":"2021-08-07T04:03:44.872108Z","shell.execute_reply.started":"2021-08-07T04:03:44.863914Z","shell.execute_reply":"2021-08-07T04:03:44.871275Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def validation(val_dataset, model):\n    ...\n    return avg_loss, acc","metadata":{"execution":{"iopub.status.busy":"2021-08-07T04:03:44.874132Z","iopub.execute_input":"2021-08-07T04:03:44.874507Z","iopub.status.idle":"2021-08-07T04:03:44.884677Z","shell.execute_reply.started":"2021-08-07T04:03:44.874473Z","shell.execute_reply":"2021-08-07T04:03:44.883885Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Improved Model: BTD (Brain Tumor Detection)","metadata":{}},{"cell_type":"code","source":"class BTD(keras.Model):\n    \"\"\" BTD stands for brain-tumor-detection \"\"\"\n    def __init__(self):\n        super().__init__()\n    \n        self.num_conv_layers = 6\n        self.conv_filters =      [16,     64,     128,        256,        512,          512]\n        self.conv_kernel_sizes = [7,      7,      7,          5,          3,            8]\n        self.conv_padding      = ['same', 'same', 'same',     'same',     'same',      'valid']\n        self.pool_kernel_sizes = [2,      2,      2,          2,          (1, 2, 2),   None]\n        self.bm_or_not =         [True,   True,   True,       True,       True,        True]\n        \n        self.convs = []\n        self.pools = []\n        self.bms   = []\n        \n        for i in range(self.num_conv_layers):\n            if self.conv_filters[i]:\n                self.convs.append(keras.layers.Conv3D(self.conv_filters[i], self.conv_kernel_sizes[i], activation='relu', padding=self.conv_padding[i]))\n            else:\n                self.convs.append(None)\n            \n            if self.pool_kernel_sizes[i]:\n                self.pools.append(keras.layers.MaxPool3D(pool_size=self.pool_kernel_sizes[i], strides=None, padding='valid', data_format=None))\n            else:\n                self.pools.append(None)\n                \n            if self.bm_or_not[i]:\n                self.bms.append(keras.layers.BatchNormalization())\n            else:\n                self.bms.append(None)\n\n        self.flatten = keras.layers.Flatten()\n        \n        self.num_linear_layers = 2\n        self.linear_dims        = [512,       1]\n        self.linear_activations = ['relu',    'sigmoid']\n        \n        self.linears = []\n        \n        for i in range(self.num_linear_layers):\n            self.linears.append(keras.layers.Dense(self.linear_dims[i], activation=self.linear_activations[i]))\n        \n    def call(self, x, verbos=0):\n        for i in range(self.num_conv_layers):\n            if self.convs[i]:\n                x = self.convs[i](x)\n                self.convs[i].output_ = x\n            if self.pools[i]:\n                x = self.pools[i](x)\n                self.pools[i].output_ = x\n            if self.bms[i]:\n                x = self.bms[i](x)\n                self.bms[i].output_ = x\n                \n            if verbos > 0:\n                print('ok', x.shape)\n            \n        x = self.flatten(x)\n        \n        for i in range(self.num_linear_layers):\n            x = self.linears[i](x)\n            \n            if verbos > 0:\n                print('ok', x.shape)\n        \n        return x","metadata":{"execution":{"iopub.status.busy":"2021-08-07T04:03:44.885985Z","iopub.execute_input":"2021-08-07T04:03:44.886355Z","iopub.status.idle":"2021-08-07T04:03:44.90448Z","shell.execute_reply.started":"2021-08-07T04:03:44.88632Z","shell.execute_reply":"2021-08-07T04:03:44.903542Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"btd = BTD()\nbtd.build(input_shape=(None, 128, 256, 256, 1))\nbtd.summary()","metadata":{"execution":{"iopub.status.busy":"2021-08-07T04:03:44.905732Z","iopub.execute_input":"2021-08-07T04:03:44.906089Z","iopub.status.idle":"2021-08-07T04:03:45.042288Z","shell.execute_reply.started":"2021-08-07T04:03:44.906054Z","shell.execute_reply":"2021-08-07T04:03:45.041497Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset = get_brain_tumor_train_dataset(using='FLAIR')\n\ntrained_btd = train(train_dataset, btd, batch_size=1, submission=SUBMISSION)","metadata":{"execution":{"iopub.status.busy":"2021-08-07T04:03:45.045008Z","iopub.execute_input":"2021-08-07T04:03:45.045342Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Train:\n    def __init__(self, dataset, \n                       model, \n                       sample,\n                       batch_size=1, \n                       EPOCHS=3,\n                       submission=False):\n        self.dataset = dataset.batch(batch_size)\n        self.model = model\n        self.sample = sample\n        self.batch_size = batch_size\n        self.EPOCHS = EPOCHS\n        self.submission = submission\n        \n        self.times_being_trained = 0\n    \n    def save_hidden_images(self, epoch, itr):\n        prob = self.model(self.sample)\n\n        for i, conv in enumerate(self.model.convs):\n            for j in range(conv.output_.shape[-1]):\n                basepath = f\"/kaggle/working/train/images_{epoch}/iteration_{itr}/conv_{i}\"\n                os.makedirs(basepath, exist_ok=True)\n                to_gif(conv.output_[0, :, :, :, i], savepath=os.path.join(basepath, f\"channel_{j}.gif\"))\n\n    def start(self):\n        \n        self.optimizer = keras.optimizers.Adam()\n        self.loss_func = keras.losses.BinaryCrossentropy()\n\n        @tf.function\n        def train_step(images, label):\n            with tf.GradientTape() as tape:\n                output = self.model(images)\n                loss = self.loss_func(label, output)\n\n            gradients = tape.gradient(loss, self.model.trainable_variables)\n            self.optimizer.apply_gradients(zip(gradients, self.model.trainable_variables))\n\n        for epoch in range(self.EPOCHS):\n            print(f\"start epoch {epoch}\")\n            for itr, (images, label) in tqdm(enumerate(self.dataset)):\n                train_step(images, label)\n\n                if itr % 100 == 0 and (not self.submission):\n                    self.save_hidden_images(epoch + 1, itr + 1)\n\n    #         checkpoint.save(file_prefix = checkpoint_prefix)\n\n      # 最后一个 epoch 结束后生成图片\n        self.save_hidden_images(\"last\", 0)\n        \n        print(\"Training Complete ... \")\n        self.times_being_trained += 1\n        \n    def report(self):\n        ...","metadata":{"execution":{"iopub.status.busy":"2021-08-08T13:26:15.91463Z","iopub.execute_input":"2021-08-08T13:26:15.915006Z","iopub.status.idle":"2021-08-08T13:26:16.000414Z","shell.execute_reply.started":"2021-08-08T13:26:15.914975Z","shell.execute_reply":"2021-08-08T13:26:15.999578Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Post Training Analysis","metadata":{}},{"cell_type":"code","source":"# !zip -r /kaggle/working/train_conv_images.zip /kaggle/working/train","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# epoch = 2\n# itr = 501\n# num_filter = 1\n# num_channel = 3\n# print(os.listdir(f\"./train/images_{epoch}/iteration_{itr}/conv_{num_filter}\"))\n# embed.embed_file(f\"./train/images_{epoch}/iteration_{itr}/conv_{num_filter}/channel_{num_channel}.gif\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Submission","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"test_dataset = get_brain_tumor_test_dataset()\n\nsubmission_df = pd.read_csv(\"../input/rsna-miccai-brain-tumor-radiogenomic-classification/sample_submission.csv\")\n\nfor i, img in enumerate(test_dataset):\n    prod = trained_btd(img)\n    prod = float(prod)\n    submission_df.loc[i, \"MGMT_value\"] = prod\n    \n    \nsubmission_df['BraTS21ID'] = submission_df['BraTS21ID'].astype(str).apply(lambda x:get_patient_id(int(x)))\nsubmission_df.set_index('BraTS21ID', inplace=True)\nsubmission_df.to_csv(\"./submission.csv\")","metadata":{"execution":{"iopub.status.busy":"2021-08-08T13:26:50.609305Z","iopub.execute_input":"2021-08-08T13:26:50.609699Z","iopub.status.idle":"2021-08-08T13:26:50.638313Z","shell.execute_reply.started":"2021-08-08T13:26:50.60965Z","shell.execute_reply":"2021-08-08T13:26:50.63737Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}