{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"SUBMISSION = True\n\n\"\"\"\n    REMEMBER!!!\n    提交之前的操作\n    1. 关闭互联网\n    2. 打开 GPU\n    3. 检查 training procedure 是否有 bug\n    4. 检查是否能正常 predict\n\n\"\"\"\n\nUSING = \"T2w\"\nBATCH_SIZE = 10\nEPOCHS = 100\nIMG_SIZE = (30, 100, 100)\nVAL = True","metadata":{"_uuid":"4e208096-426e-4384-b7b9-ca493b6a3ef7","_cell_guid":"7868e9e7-d35b-46a2-af70-a53bc8aba013","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os    # operating system\nimport re    # regular expression\nimport glob   # read files with regular expression\nimport numpy as np   # numerical\nimport scipy as sp    # scientific\nimport pandas as pd    # table management\nimport seaborn as sns    # plot for data scientist\nfrom PIL import Image    # image management\nfrom tqdm import tqdm    # progress bar\nfrom skimage import transform\n\nimport matplotlib.pyplot as plt    # the most popular plot lib\nfrom mpl_toolkits.mplot3d import Axes3D    \n%matplotlib inline\n\nimport pydicom   # .dicom files management\nfrom pydicom.pixel_data_handlers.util import apply_voi_lut\n\n# For gif creation\nimport imageio\n\n\n# tf\nimport tensorflow as tf\n\n# keras\nimport keras\n\nfrom data_processing import *","metadata":{"execution":{"iopub.status.busy":"2021-09-01T07:54:19.624344Z","iopub.execute_input":"2021-09-01T07:54:19.624666Z","iopub.status.idle":"2021-09-01T07:54:24.797723Z","shell.execute_reply.started":"2021-09-01T07:54:19.624637Z","shell.execute_reply":"2021-09-01T07:54:24.796875Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"ds = get_2d_train_dataset_multiload(train_df.iloc[:5])","metadata":{"execution":{"iopub.status.busy":"2021-09-01T07:54:41.623910Z","iopub.execute_input":"2021-09-01T07:54:41.624299Z","iopub.status.idle":"2021-09-01T07:54:53.516518Z","shell.execute_reply.started":"2021-09-01T07:54:41.624268Z","shell.execute_reply":"2021-09-01T07:54:53.514443Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"loading data buffer with size 5\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-4-8a197b96ac5f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_2d_train_dataset_multiload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/kaggle/usr/lib/data_processing/data_processing.py\u001b[0m in \u001b[0;36mget_2d_train_dataset_multiload\u001b[0;34m(df_of_labels, using, maxlen, img_size)\u001b[0m\n\u001b[1;32m    327\u001b[0m         \u001b[0mcurrent_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_s\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 329\u001b[0;31m         \u001b[0mcurrent_imgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_size\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcurrent_imgs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    330\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0mlightnesses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlightness\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimgs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/kaggle/usr/lib/data_processing/data_processing.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    327\u001b[0m         \u001b[0mcurrent_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_s\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 329\u001b[0;31m         \u001b[0mcurrent_imgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_size\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcurrent_imgs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    330\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0mlightnesses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlightness\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimgs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/kaggle/usr/lib/data_processing/data_processing.py\u001b[0m in \u001b[0;36mresize\u001b[0;34m(image, target_size)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m     \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/skimage/transform/_warps.py\u001b[0m in \u001b[0;36mresize\u001b[0;34m(image, output_shape, order, mode, cval, clip, preserve_range, anti_aliasing, anti_aliasing_sigma)\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0moutput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0moutput_ndim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m     \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0moutput_ndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0;31m# append dimensions to input_shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'shape'"],"ename":"AttributeError","evalue":"'str' object has no attribute 'shape'","output_type":"error"}]},{"cell_type":"code","source":"for img, label in ds:\n    print(img.shape, label)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from __future__ import division\n\nimport six\nfrom keras.models import Model\nfrom keras.layers import (\n    Input,\n    Activation,\n    Dense,\n    Flatten\n)\nfrom keras.layers.convolutional import (\n    Conv3D,\n    MaxPooling3D,\n    AveragePooling3D\n)\nfrom keras.layers.merge import add\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.regularizers import l2\nfrom keras import backend as K\nfrom keras.metrics import mean_absolute_error\nimport keras\nfrom keras.optimizers import Adam\nfrom keras.losses import binary_crossentropy\n\ndef sensitivity(y_true, y_pred):\n    true_positives = keras.backend.sum(keras.backend.round(keras.backend.clip(y_true * y_pred, 0, 1)))\n    possible_positives = keras.backend.sum(keras.backend.round(keras.backend.clip(y_true, 0, 1)))\n    return true_positives / (possible_positives + keras.backend.epsilon())\n\n\ndef specificity(y_true, y_pred):\n    true_negatives = keras.backend.sum(keras.backend.round(keras.backend.clip((1-y_true) * (1-y_pred), 0, 1)))\n    possible_negatives = keras.backend.sum(keras.backend.round(keras.backend.clip(1-y_true, 0, 1)))\n    return true_negatives / (possible_negatives + keras.backend.epsilon())\n\n\ndef j_stat(y_true, y_pred):\n    return sensitivity(y_true, y_pred) + specificity(y_true, y_pred) - 1\n\n\ndef compare_scores(y_true, y_pred, comparison=0, metric=mean_absolute_error):\n    keras_comparison = keras.backend.variable(comparison)\n    return metric(y_true, y_pred) - metric(y_true, keras_comparison)\n\n\ndef _bn_relu(input):\n    \"\"\"Helper to build a BN -> relu block\n    \"\"\"\n    norm = BatchNormalization(axis=4)(input)\n    return Activation(\"relu\")(norm)\n\n\ndef _conv_bn_relu(**conv_params):\n    \"\"\"Helper to build a conv -> BN -> relu block\n    \"\"\"\n    filters = conv_params[\"filters\"]\n    kernel_size = conv_params[\"kernel_size\"]\n    strides = conv_params.setdefault(\"strides\", (1, 1, 1))\n    kernel_initializer = conv_params.setdefault(\"kernel_initializer\", \"he_normal\")\n    padding = conv_params.setdefault(\"padding\", \"same\")\n    kernel_regularizer = conv_params.setdefault(\"kernel_regularizer\", l2(1.e-4))\n\n    def f(input):\n        conv = Conv3D(filters=filters, kernel_size=kernel_size,\n                      strides=strides, padding=padding,\n                      kernel_initializer=kernel_initializer,\n                      kernel_regularizer=None)(input)\n        return _bn_relu(conv)\n\n    return f\n\n\ndef _bn_relu_conv(**conv_params):\n    \"\"\"Helper to build a BN -> relu -> conv block.\n    This is an improved scheme proposed in http://arxiv.org/pdf/1603.05027v2.pdf\n    \"\"\"\n    filters = conv_params[\"filters\"]\n    kernel_size = conv_params[\"kernel_size\"]\n    strides = conv_params.setdefault(\"strides\", (1, 1, 1))\n    kernel_initializer = conv_params.setdefault(\"kernel_initializer\", \"he_normal\")\n    padding = conv_params.setdefault(\"padding\", \"same\")\n    kernel_regularizer = conv_params.setdefault(\"kernel_regularizer\", l2(1.e-4))\n\n    def f(input):\n        activation = _bn_relu(input)\n        return Conv3D(filters=filters, kernel_size=kernel_size,\n                      strides=strides, padding=padding,\n                      kernel_initializer=kernel_initializer,\n                      kernel_regularizer=None)(activation)\n\n    return f\n\n\ndef _shortcut(input, residual):\n    \"\"\"Adds a shortcut between input and residual block and merges them with \"sum\"\n    \"\"\"\n    # Expand channels of shortcut to match residual.\n    # Stride appropriately to match residual (width, height)\n    # Should be int if network architecture is correctly configured.\n    input_shape = K.int_shape(input)\n    residual_shape = K.int_shape(residual)\n    stride_width = int(round(input_shape[1] / residual_shape[1]))\n    stride_height = int(round(input_shape[2] / residual_shape[2]))\n    stride_depth = int(round(input_shape[3] / residual_shape[3]))\n    equal_channels = input_shape[4] == residual_shape[4]\n\n    shortcut = input\n    # 1 X 1 conv if reduced_shape is different. Else identity.\n    if stride_width > 1 or stride_height > 1 or not equal_channels:\n        shortcut = Conv3D(filters=residual_shape[4],\n                          kernel_size=(1, 1, 1),\n                          strides=(stride_width, stride_height, stride_depth),\n                          padding=\"valid\",\n                          kernel_initializer=\"he_normal\",\n                          kernel_regularizer=None)(input)\n\n    return add([shortcut, residual])\n\n\ndef _residual_block(block_function, filters, repetitions, is_first_layer=False):\n    \"\"\"Builds a residual block with repeating bottleneck blocks.\n    \"\"\"\n    def f(input):\n        for i in range(repetitions):\n            init_strides = (1, 1, 1)\n            if i == 0 and not is_first_layer:\n                init_strides = (2, 2, 2)\n            input = block_function(filters=filters, init_strides=init_strides,\n                                   is_first_block_of_first_layer=(is_first_layer and i == 0))(input)\n        return input\n\n    return f\n\n\ndef basic_block(filters, init_strides=(1, 1, 1), is_first_block_of_first_layer=False):\n    \"\"\"Basic 3 X 3 convolution blocks for use on resnets with layers <= 34.\n    Follows improved proposed scheme in http://arxiv.org/pdf/1603.05027v2.pdf\n    \"\"\"\n    def f(input):\n\n        if is_first_block_of_first_layer:\n            # don't repeat bn->relu since we just did bn->relu->maxpool\n            conv1 = Conv3D(filters=filters, kernel_size=(3, 3, 3),\n                           strides=init_strides,\n                           padding=\"same\",\n                           kernel_initializer=\"he_normal\",\n                           kernel_regularizer=None)(input)\n        else:\n            conv1 = _bn_relu_conv(filters=filters, kernel_size=(3, 3, 3),\n                                  strides=init_strides)(input)\n\n        residual = _bn_relu_conv(filters=filters, kernel_size=(3, 3, 3))(conv1)\n        return _shortcut(input, residual)\n\n    return f\n\n\ndef bottleneck(filters, init_strides=(1, 1, 1), is_first_block_of_first_layer=False):\n    \"\"\"Bottleneck architecture for > 34 layer encoder.\n    Follows improved proposed scheme in http://arxiv.org/pdf/1603.05027v2.pdf\n    Returns:\n        adjacency_matrix final conv layer of filters * 4\n    \"\"\"\n    def f(input):\n\n        if is_first_block_of_first_layer:\n            # don't repeat bn->relu since we just did bn->relu->maxpool\n            conv_1_1 = Conv3D(filters=filters, kernel_size=(1, 1, 1),\n                              strides=init_strides,\n                              padding=\"same\",\n                              kernel_initializer=\"he_normal\",\n                              kernel_regularizer=None)(input)\n        else:\n            conv_1_1 = _bn_relu_conv(filters=filters, kernel_size=(1, 1, 1),\n                                     strides=init_strides)(input)\n\n        conv_3_3 = _bn_relu_conv(filters=filters, kernel_size=(3, 3, 3))(conv_1_1)\n        residual = _bn_relu_conv(filters=filters * 4, kernel_size=(1, 1, 1))(conv_3_3)\n        return _shortcut(input, residual)\n\n    return f\n\n\ndef _get_block(identifier):\n    if isinstance(identifier, six.string_types):\n        res = globals().get(identifier)\n        if not res:\n            raise ValueError('Invalid {}'.format(identifier))\n        return res\n    return identifier\n\n\nclass ResnetBuilder(object):\n    @staticmethod\n    def build(input_shape, num_outputs, block_fn, repetitions, activation=\"sigmoid\", kernel_initializer='he_normal',\n              n_dense_layers=1):\n        \"\"\"Builds a custom ResNet like architecture.\n        Args:\n            input_shape: The input reduced_shape in the form (nb_rows, nb_cols, nb_z_cols, nb_channels)\n            num_outputs: The number of outputs at final activation layer\n            block_fn: The block function to use. This is either `basic_block` or `bottleneck`.\n                The original paper used basic_block for layers < 50\n            repetitions: Number of repetitions of various block units.\n                At each block unit, the number of filters are doubled and the input size is halved\n            activation: default is 'softmax'\n            kernel_initializer: default is 'he_normal'\n        Returns:\n            The keras `Model`.\n        \"\"\"\n\n        # Load function from str if needed.\n        block_fn = _get_block(block_fn)\n\n        input = Input(shape=input_shape)\n        conv1 = _conv_bn_relu(filters=64, kernel_size=(7, 7, 7), strides=(2, 2, 2))(input)\n        pool1 = MaxPooling3D(pool_size=(3, 3, 3), strides=(2, 2, 2), padding=\"same\")(conv1)\n\n        block = pool1\n        filters = 64\n        for i, r in enumerate(repetitions):\n            block = _residual_block(block_fn, filters=filters, repetitions=r, is_first_layer=(i == 0))(block)\n            filters *= 2\n\n        # Last activation\n        block = _bn_relu(block)\n\n        # Classifier block\n        block_shape = K.int_shape(block)\n        pool2 = AveragePooling3D(pool_size=(block_shape[1], block_shape[2], block_shape[3]),\n                                 strides=(1, 1, 1))(block)\n        flatten1 = Flatten()(pool2)\n        dense_input = flatten1\n        for i in range(n_dense_layers):\n            if (i + 1) < n_dense_layers:\n                layer_activation = ReLU\n            else:\n                layer_activation = activation\n            dense_input = Dense(units=num_outputs,\n                                kernel_initializer=kernel_initializer,\n                                activation=layer_activation)(dense_input)\n\n        model = Model(inputs=input, outputs=dense_input)\n        return model\n\n    @staticmethod\n    def build_resnet_18(input_shape, num_outputs, **kwargs):\n        return ResnetBuilder.build(input_shape, num_outputs, basic_block, [2, 2, 2, 2], **kwargs)\n\n    @staticmethod\n    def build_resnet_34(input_shape, num_outputs, **kwargs):\n        return ResnetBuilder.build(input_shape, num_outputs, basic_block, [3, 4, 6, 3], **kwargs)\n\n    @staticmethod\n    def build_resnet_50(input_shape, num_outputs, **kwargs):\n        return ResnetBuilder.build(input_shape, num_outputs, bottleneck, [3, 4, 6, 3], **kwargs)\n\n    @staticmethod\n    def build_resnet_101(input_shape, num_outputs, **kwargs):\n        return ResnetBuilder.build(input_shape, num_outputs, bottleneck, [3, 4, 23, 3], **kwargs)\n\n    @staticmethod\n    def build_resnet_152(input_shape, num_outputs, **kwargs):\n        return ResnetBuilder.build(input_shape, num_outputs, bottleneck, [3, 8, 36, 3], **kwargs)","metadata":{"execution":{"iopub.status.busy":"2021-09-01T07:50:39.118666Z","iopub.execute_input":"2021-09-01T07:50:39.118993Z","iopub.status.idle":"2021-09-01T07:50:39.161538Z","shell.execute_reply.started":"2021-09-01T07:50:39.118963Z","shell.execute_reply":"2021-09-01T07:50:39.160608Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset, val_dataset = train_val_split(0.95, img_size=IMG_SIZE, using=USING)\n\nif not VAL:\n    val_dataset = None","metadata":{"execution":{"iopub.status.busy":"2021-09-01T06:26:19.891892Z","iopub.execute_input":"2021-09-01T06:26:19.893972Z","iopub.status.idle":"2021-09-01T06:45:12.477511Z","shell.execute_reply.started":"2021-09-01T06:26:19.893935Z","shell.execute_reply":"2021-09-01T06:45:12.476698Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = ResnetBuilder.build_resnet_18(input_shape=[30, 100, 100, 1], num_outputs=1)\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2021-09-01T07:24:38.217944Z","iopub.execute_input":"2021-09-01T07:24:38.218398Z","iopub.status.idle":"2021-09-01T07:24:38.609747Z","shell.execute_reply.started":"2021-09-01T07:24:38.218356Z","shell.execute_reply":"2021-09-01T07:24:38.608805Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sanity_x = tf.random.normal([5, 30, 100, 100, 1])\npredicted_label = model(sanity_x)\nprint(predicted_label)","metadata":{"execution":{"iopub.status.busy":"2021-09-01T07:24:44.213996Z","iopub.execute_input":"2021-09-01T07:24:44.21437Z","iopub.status.idle":"2021-09-01T07:24:44.255079Z","shell.execute_reply.started":"2021-09-01T07:24:44.214337Z","shell.execute_reply":"2021-09-01T07:24:44.254044Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(optimizer=Adam(learning_rate=0.01),\n                      loss=binary_crossentropy,\n                      metrics=['accuracy'])\nmodel.fit(train_dataset.batch(32),epochs=20,validation_data=val_dataset.batch(32),\n                       validation_steps=1)","metadata":{"execution":{"iopub.status.busy":"2021-09-01T07:24:46.8338Z","iopub.execute_input":"2021-09-01T07:24:46.834139Z","iopub.status.idle":"2021-09-01T07:27:11.643315Z","shell.execute_reply.started":"2021-09-01T07:24:46.834106Z","shell.execute_reply":"2021-09-01T07:27:11.642333Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_dataset = get_brain_tumor_test_dataset(img_size=IMG_SIZE, using=USING).batch(1)\n\nsubmission_df = pd.read_csv(\"../input/rsna-miccai-brain-tumor-radiogenomic-classification/sample_submission.csv\")\n\n# print(submission_df[\"MGMT_value\"].dtype)\nfor i, img in enumerate(test_dataset):\n    prod = model(img)\n#     prod = keras.activations.sigmoid(prod)[0, 0]\n    prod = float(prod)\n    submission_df.loc[i, \"MGMT_value\"] = prod\n    \n\nsubmission_df['BraTS21ID'] = submission_df['BraTS21ID'].astype(str).apply(lambda x:get_patient_id(int(x)))\nsubmission_df.set_index('BraTS21ID', inplace=True)\nsubmission_df.to_csv(\"./submission.csv\")","metadata":{"execution":{"iopub.status.busy":"2021-09-01T07:27:49.005921Z","iopub.execute_input":"2021-09-01T07:27:49.006282Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_df","metadata":{"execution":{"iopub.status.busy":"2021-09-01T07:51:06.26827Z","iopub.execute_input":"2021-09-01T07:51:06.26869Z","iopub.status.idle":"2021-09-01T07:51:06.294525Z","shell.execute_reply.started":"2021-09-01T07:51:06.268649Z","shell.execute_reply":"2021-09-01T07:51:06.293161Z"},"trusted":true},"execution_count":null,"outputs":[]}]}